{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "n_embedding = 8\n",
    "n_layers = 12"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class RWKV_CM(torch.jit.ScriptModule):\n",
    "    def __init__(self, config, index):\n",
    "        super(RWKV_CM, self).__init__()\n",
    "        layers = config.number_of_layers\n",
    "        hidden_size = config.hidden_size\n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
    "        with torch.no_grad():\n",
    "            time_ratio = 1 - (index / layers)\n",
    "            x = torch.ones(1, 1, hidden_size)\n",
    "            for i in range(hidden_size):\n",
    "                x[0, 0, i] = i / hidden_size\n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, time_ratio))\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, time_ratio))\n",
    "\n",
    "        h_up = hidden_size * 4\n",
    "\n",
    "        self.key = nn.Linear(hidden_size, h_up, bias=False)\n",
    "        self.value = nn.Linear(h_up, h_up, bias=False)\n",
    "        self.r = nn.Linear(h_up, hidden_size, bias=False)\n",
    "\n",
    "        self.value.scale_init = 0\n",
    "        self.r.scale_init = 0\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        xx = self.time_shift(x)\n",
    "        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n",
    "        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n",
    "        k = self.key(xk)\n",
    "        kv = self.value(F.silu(k))\n",
    "        out = F.sigmoid(self.r(xr)) + kv\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RWKV_TimeMix(torch.jit.ScriptModule):\n",
    "    def __init__(self, config, index):\n",
    "        super(RWKV_TimeMix, self).__init__()\n",
    "        layers = config.number_of_layers\n",
    "        hidden_size = config.hidden_size\n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
    "        with torch.no_grad():\n",
    "            time_ratio_0_to_1 = (index / (layers - 1))\n",
    "            time_ratio_1_to_pz = (1 - (index / layers))\n",
    "            decay_speed = torch.ones(hidden_size)\n",
    "            for i in range(hidden_size):\n",
    "                decay_speed[i] = -5 + 8 * (i / (hidden_size - 1)) ** (0.7 + 1.3 * time_ratio_0_to_1)\n",
    "            self.time_decay = nn.Parameter(decay_speed)\n",
    "            zigzag = (torch.tensor([(i + 1) % 3 - 1 for i in range(hidden_size)]) * 0.5)\n",
    "            self.time_first = nn.Parameter(torch.ones(hidden_size) * math.log(0.3) + zigzag)\n",
    "            x = torch.ones(1, 1, hidden_size)\n",
    "            for i in range(hidden_size):\n",
    "                x[0, 0, i] = i / hidden_size\n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, time_ratio_1_to_pz))\n",
    "            self.time_mix_v = nn.Parameter(torch.pow(x, time_ratio_1_to_pz) + 0.3 * time_ratio_0_to_1)\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, 0.5 * time_ratio_1_to_pz))\n",
    "        h_up = hidden_size * 4\n",
    "        self.k = nn.Linear(hidden_size, h_up, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, h_up, bias=False)\n",
    "        self.r = nn.Linear(hidden_size, h_up, bias=False)\n",
    "        self.o = nn.Linear(h_up, hidden_size, bias=False)\n",
    "        self.k.scale_init = 0\n",
    "        self.r.scale_init = 0\n",
    "        self.o.scale_init = 0\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def func_jump(self, x):\n",
    "        xx = self.time_shift(x)\n",
    "        k = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n",
    "        v = x * self.time_mix_v + xx * (1 - self.time_mix_v)\n",
    "        r = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n",
    "\n",
    "        k = self.k(k)\n",
    "        v = self.v(v)\n",
    "        sr = torch.sigmoid(self.r(r))\n",
    "        return sr, k, v\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        sr, k, v = self.jit_func(x)\n",
    "        # TODO: implement run_cuda in pytorch\n",
    "        # rwkv = sr * RUN_CUDA(B, T, C, self.time_decay, self.time_first, k, v)\n",
    "        # rwkv = self.output(rwkv)\n",
    "        # return rwkv\n",
    "        return ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}