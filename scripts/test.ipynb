{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import erutils\n",
    "import sentencepiece\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    Dropout = 0.2\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device = 'cpu'\n",
    "\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=200):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # create constant 'pe' matrix with values dependant on\n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        # add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        # print(x.shape)\n",
    "        x = x + Variable(self.pe[:, :seq_len], requires_grad=False).cuda()\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2, x2, x2, mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "\n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model).cuda()\n",
    "\n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,\n",
    "                                           src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "\n",
    "# We can then build a convenient cloning function that can generate multiple layers:\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def tokenize_words(word: list, first_word_token: int = 0, swap: int = 1001, last_word_token: int = 1002,\n",
    "                   pad_index: int = 1003):\n",
    "    \"\"\"\n",
    "    :param swap:\n",
    "    :param pad_index:\n",
    "    :param last_word_token:\n",
    "    :param first_word_token:\n",
    "    :param word: index\n",
    "    :return: 0 for start token | 1002 for end token\n",
    "    \"\"\"\n",
    "    word = [(swap if w == 0 else w) for w in word]\n",
    "    word = [first_word_token] + word\n",
    "    word.append(last_word_token)\n",
    "    word.append(pad_index)\n",
    "    return word\n",
    "\n",
    "\n",
    "sentence = sentencepiece.SentencePieceProcessor()\n",
    "sentence.Load(model_file='../tokenizer_model/test_model.model')\n",
    "\n",
    "\n",
    "def fix_data(data):\n",
    "    # data = itertools.islice(data.items(), 500)\n",
    "    for d in data:\n",
    "        question = data[d]['question']\n",
    "        answers = data[d]['answers']\n",
    "        encoded_question = tokenize_words(sentence.Encode(question))\n",
    "        encoded_answers = tokenize_words(sentence.Encode(answers))\n",
    "        yield encoded_question, encoded_answers\n",
    "\n",
    "\n",
    "def save_model(name: str = 'model_save.pt', **kwargs):\n",
    "    v = {**kwargs}\n",
    "\n",
    "    torch.save(v, name)\n",
    "\n",
    "\n",
    "def make_src_mask(src, src_pad_index):\n",
    "    src_mask = (src != src_pad_index).unsqueeze(1).unsqueeze(2)\n",
    "    # (N, 1, 1, src_len)\n",
    "    return src_mask.to(src.device)\n",
    "\n",
    "\n",
    "def make_trg_mask(trg):\n",
    "    N, trg_len = trg.shape\n",
    "    trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "        N, 1, trg_len, trg_len\n",
    "    )\n",
    "\n",
    "    return trg_mask.to(trg.device)\n",
    "\n",
    "\n",
    "data = erutils.read_json('../data/train-v2.0-cleared.json')\n",
    "\n",
    "transformer = Transformer(src_vocab=1004, trg_vocab=1004, d_model=512, heads=4, N=6).to(\n",
    "    Config.device)\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "print(sum(s.numel() for s in transformer.parameters()) / 1e6, \" Million Parameters Are In MODEL\")\n",
    "optim = torch.optim.AdamW(transformer.parameters(), 4e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "epochs = 1000\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "# xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "# xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "text = 'hello im here to be tested'\n",
    "token = torch.tensor([0, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "Seq = T.Sequential(\n",
    "    T.SentencePieceTokenizer('../tokenizer_model/xlmr.sentencepiece.bpe.model'),\n",
    "    # T.VocabTransform('../tokenizer_model/xlmr.vocab.pt'),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(bos_idx, True),\n",
    "    T.AddToken(eos_idx, False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IterableWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m YahooAnswers\n\u001B[0;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[1;32m----> 5\u001B[0m train_datapipe \u001B[38;5;241m=\u001B[39m \u001B[43mYahooAnswers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\Python\\Ai-Projects\\venv\\lib\\site-packages\\torchtext\\data\\datasets_utils.py:193\u001B[0m, in \u001B[0;36m_create_dataset_directory.<locals>.decorator.<locals>.wrapper\u001B[1;34m(root, *args, **kwargs)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(new_root):\n\u001B[0;32m    192\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(new_root, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(root\u001B[38;5;241m=\u001B[39mnew_root, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\Programming\\Python\\Ai-Projects\\venv\\lib\\site-packages\\torchtext\\data\\datasets_utils.py:155\u001B[0m, in \u001B[0;36m_wrap_split_argument_with_fn.<locals>.new_fn\u001B[1;34m(root, split, **kwargs)\u001B[0m\n\u001B[0;32m    153\u001B[0m result \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m _check_default_set(split, splits, fn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m):\n\u001B[1;32m--> 155\u001B[0m     result\u001B[38;5;241m.\u001B[39mappend(fn(root, item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _wrap_datasets(\u001B[38;5;28mtuple\u001B[39m(result), split)\n",
      "File \u001B[1;32mE:\\Programming\\Python\\Ai-Projects\\venv\\lib\\site-packages\\torchtext\\datasets\\yahooanswers.py:81\u001B[0m, in \u001B[0;36mYahooAnswers\u001B[1;34m(root, split)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_module_available(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchdata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m(\n\u001B[0;32m     78\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPackage `torchdata` not found. Please install following instructions at https://github.com/pytorch/data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     79\u001B[0m     )\n\u001B[1;32m---> 81\u001B[0m url_dp \u001B[38;5;241m=\u001B[39m \u001B[43mIterableWrapper\u001B[49m([URL])\n\u001B[0;32m     83\u001B[0m cache_compressed_dp \u001B[38;5;241m=\u001B[39m url_dp\u001B[38;5;241m.\u001B[39mon_disk_cache(\n\u001B[0;32m     84\u001B[0m     filepath_fn\u001B[38;5;241m=\u001B[39mpartial(_filepath_fn, root),\n\u001B[0;32m     85\u001B[0m     hash_dict\u001B[38;5;241m=\u001B[39m{_filepath_fn(root): MD5},\n\u001B[0;32m     86\u001B[0m     hash_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmd5\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     87\u001B[0m )\n\u001B[0;32m     88\u001B[0m cache_compressed_dp \u001B[38;5;241m=\u001B[39m GDriveReader(cache_compressed_dp)\u001B[38;5;241m.\u001B[39mend_caching(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m, same_filepath_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'IterableWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchtext.datasets import YahooAnswers\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_datapipe = YahooAnswers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}